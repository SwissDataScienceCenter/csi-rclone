---
# Source: csi-rclone/templates/csi-rclone-namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: csi-rclone
---
# Source: csi-rclone/templates/csi-controller-rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: csi-rclone-controller
  namespace: csi-rclone
  labels:
    helm.sh/chart: csi-rclone-0.1.0
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    {}
---
# Source: csi-rclone/templates/csi-nodeplugin-rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: csi-rclone-nodeplugin
  namespace: csi-rclone
  labels:
    helm.sh/chart: csi-rclone-0.1.0
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    {}
---
# Source: csi-rclone/templates/csi-rclone-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: rclone-provisioner-secret
  namespace: csi-rclone
type: Opaque
# options and args for provisioner (mkdir and purge)
# do NOT put vfs and cache args here.
stringData:
  remote: "s3"
  remotePath: "projectname"
  s3-provider: "Minio"
  s3-endpoint: "http://minio.munio:9000"
  s3-access-key-id: "ACCESS_KEY_ID"
  s3-secret-access-key: "SECRET_ACCESS_KEY"
---
# Source: csi-rclone/templates/csi-rclone-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: rclone-secret
  namespace: csi-rclone
type: Opaque
# options and args for mounting
# Put VFS and cache args here.
stringData:
  remote: "s3"
  remotePath: "projectname"
  vfs-cache-mode: "writes"
  s3-provider: "Minio"
  s3-endpoint: "http://minio.munio:9000"
  s3-access-key-id: "ACCESS_KEY_ID"
  s3-secret-access-key: "SECRET_ACCESS_KEY"
---
# Source: csi-rclone/templates/csi-rclone-storageclass.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: csi-rclone
  labels:
    helm.sh/chart: csi-rclone-0.1.0
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.0"
    app.kubernetes.io/managed-by: Helm
provisioner: csi-rclone
# TODO: check what it does
volumeBindingMode: Immediate
reclaimPolicy: Delete
parameters:
  csi.storage.k8s.io/provisioner-secret-name: rclone-provisioner-secret
  csi.storage.k8s.io/provisioner-secret-namespace: csi-rclone
  csi.storage.k8s.io/node-publish-secret-name: rclone-secret
  csi.storage.k8s.io/node-publish-secret-namespace: csi-rclone
---
# Source: csi-rclone/templates/csi-controller-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: csi-rclone-external-controller
  labels:
    helm.sh/chart: csi-rclone-0.1.0
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.0"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:
  - ""
  resources:
  - persistentvolumes
  verbs:
  - get
  - list
  - watch
  - update
- apiGroups:
  - ""
  resources: 
  - "secrets"
  - "secret"
  verbs:
  - "get"
  - "list"
  - "create" # TODO: check if necessary
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - csi.storage.k8s.io
  resources:
  - csinodeinfos
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - storage.k8s.io
  resources:
  - volumeattachments
  verbs:
  - get
  - list
  - watch
  - update
- apiGroups:
  - storage.k8s.io
  resources:
  - volumeattachments
  verbs:
  - get
  - list
  - watch
  - update
- apiGroups:
  - storage.k8s.io
  resources:
  - volumeattachments/status
  verbs:
  - patch
- apiGroups:
  - coordination.k8s.io
  resources:
  - leases
  verbs:
  - get
  - create
  - update
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
---
# Source: csi-rclone/templates/csi-controller-rbac.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: csi-rclone-external-provisioner-runner
  labels:
    helm.sh/chart: csi-rclone-0.1.0
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.0"
    app.kubernetes.io/managed-by: Helm
rules:
  # The following rule should be uncommented for plugins that require secrets
  # for provisioning.
  - apiGroups: 
    - ""
    resources:
    - "secrets"
    verbs: 
    - "get"
    - "list"
  - apiGroups:
    - ""
    resources:
    - "persistentvolumes"
    verbs: 
    - "get"
    - "list"
    - "watch"
    - "create"
    - "delete"
  - apiGroups: 
    - ""
    resources:
    - "persistentvolumeclaims"
    verbs:
    - "get"
    - "list"
    - "watch"
    - "update"
  - apiGroups: 
    - "storage.k8s.io"
    resources:
    - "storageclasses"
    verbs: 
    - "get"
    - "list"
    - "watch"
  - apiGroups:
    - ""
    resources:
    - "events"
    verbs:
    - "list"
    - "watch"
    - "create"
    - "update"
    - "patch"
  - apiGroups: 
    - "snapshot.storage.k8s.io"
    resources: 
    - "volumesnapshots"
    verbs: 
    - "get"
    - "list"
  - apiGroups: 
    - "snapshot.storage.k8s.io"
    resources: 
    - "volumesnapshotcontents"
    verbs: 
    - "get"
    - "list"
  - apiGroups: 
    - "storage.k8s.io"
    resources: 
    - "csinodes"
    verbs: 
    - "get"
    - "list"
    - "watch"
  - apiGroups:
    - ""
    resources: 
    - "nodes"
    verbs: 
    - "get"
    - "list"
    - "watch"
  # Access to volumeattachments is only needed when the CSI driver
  # has the PUBLISH_UNPUBLISH_VOLUME controller capability.
  # In that case, external-provisioner will watch volumeattachments
  # to determine when it is safe to delete a volume.
  - apiGroups: 
    - "storage.k8s.io"
    resources: 
    - "volumeattachments"
    verbs: 
    - "get"
    - "list"
    - "watch"
---
# Source: csi-rclone/templates/csi-nodeplugin-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: csi-rclone-nodeplugin
  labels:
    helm.sh/chart: csi-rclone-0.1.0
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.0"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:
  - ""
  resources:
  - persistentvolumes
  verbs:
  - get
  - list
  - watch
  - update
- apiGroups:
  - ""
  resources:
  - secrets
  - secret
  verbs:
  - get
  - list
  - create
  - delete
- apiGroups:
  - ""
  resources: 
  - pods
  verbs:
  - list
  - watch
- apiGroups:
  - apps
  resources:
  - deployments
  - deploy
  - deployment
  verbs: 
  - get
  - list
  - create
  - delete
  - watch
  - patch
  - update
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - get
  - list
  - watch
  - update
- apiGroups:
  - storage.k8s.io
  resources:
  - volumeattachments
  verbs:
  - get
  - list
  - watch
  - update
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - patch
---
# Source: csi-rclone/templates/csi-controller-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: csi-rclone-attacher-role
  labels:
    helm.sh/chart: csi-rclone-0.1.0
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.0"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: 'csi-rclone-external-controller'
subjects:
- kind: ServiceAccount
  name: 'csi-rclone-controller'
  namespace: csi-rclone
---
# Source: csi-rclone/templates/csi-controller-rbac.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: csi-rclone-provisioner-role
  labels:
    helm.sh/chart: csi-rclone-0.1.0
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.0"
    app.kubernetes.io/managed-by: Helm
subjects:
  - kind: ServiceAccount
    name: 'csi-rclone-controller'
    namespace: 'csi-rclone'
roleRef:
  kind: ClusterRole
  name: 'csi-rclone-external-provisioner-runner'
  apiGroup: rbac.authorization.k8s.io
---
# Source: csi-rclone/templates/csi-nodeplugin-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: csi-rclone-nodeplugin
  labels:
    helm.sh/chart: csi-rclone-0.1.0
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.0"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: 'csi-rclone-nodeplugin'
subjects:
- kind: ServiceAccount
  name: 'csi-rclone-nodeplugin'
  namespace: 'csi-rclone'
---
# Source: csi-rclone/templates/csi-controller-rbac.yaml
# Provisioner must be able to work with endpoints in current namespace
# if (and only if) leadership election is enabled
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: csi-rclone-external-provisioner-cfg
  namespace: csi-rclone
rules:
# Only one of the following rules for endpoints or leases is required based on
# what is set for `--leader-election-type`. Endpoints are deprecated in favor of Leases.
- apiGroups: 
  - ""
  resources: 
  - "endpoints"
  verbs:
  - "get"
  - "watch"
  - "list"
  - "delete"
  - "update"
  - "create"
- apiGroups: 
  - "coordination.k8s.io"
  resources:
  - "leases"
  verbs: 
  - "get"
  - "watch"
  - "list"
  - "delete"
  - "update"
  - "create"
# Permissions for CSIStorageCapacity are only needed enabling the publishing
# of storage capacity information.
- apiGroups: 
  - "storage.k8s.io"
  resources: 
  - "csistoragecapacities"
  verbs: 
  - "get"
  - "list"
  - "watch"
  - "create"
  - "update"
  - "patch"
  - "delete"
# The GET permissions below are needed for walking up the ownership chain
# for CSIStorageCapacity. They are sufficient for deployment via
# StatefulSet (only needs to get Pod) and Deployment (needs to get
# Pod and then ReplicaSet to find the Deployment).
- apiGroups: 
  - ""
  resources: 
  - "pods"
  verbs: 
  - "get"
---
# Source: csi-rclone/templates/csi-controller-rbac.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: csi-rclone-provisioner-role-cfg
  namespace: 'csi-rclone'
subjects:
  - kind: ServiceAccount
    name: csi-rclone-controller
    namespace: csi-rclone
roleRef:
  kind: Role
  name: csi-rclone-external-provisioner-cfg
---
# Source: csi-rclone/templates/csi-nodeplugin-rclone.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: csi-rclone-nodeplugin
  namespace: csi-rclone
  labels:
    helm.sh/chart: csi-rclone-0.1.0
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      app: csi-nodeplugin-rclone
      app.kubernetes.io/name: csi-rclone
      app.kubernetes.io/instance: csi-rclone
  template:
    metadata:
      labels:
        app: csi-nodeplugin-rclone
        app.kubernetes.io/name: csi-rclone
        app.kubernetes.io/instance: csi-rclone
    spec:
      serviceAccountName: csi-rclone-nodeplugin
      dnsPolicy: ClusterFirstWithHostNet
      hostNetwork: true
      containers:
      - args:
        - --v=5
        - --csi-address=/plugin/csi.sock
        - --kubelet-registration-path=/var/lib/kubelet/plugins/csi-rclone/csi.sock
        env:
        - name: KUBE_NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: KUBERNETES_CLUSTER_DOMAIN
          value: "cluster.local"
        image: k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.4.0
        imagePullPolicy: IfNotPresent
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - -c
              - rm -rf /registration/csi-rclone /registration/csi-rclone-reg.sock
        name: node-driver-registrar
        resources: {}
        volumeMounts:
        - mountPath: /plugin
          name: plugin-dir
        - mountPath: /registration
          name: registration-dir
      - args:
        - /bin/csi-rclone-plugin
        - run
        - --nodeid=$(NODE_ID)
        - --endpoint=$(CSI_ENDPOINT)
        env:
        - name: NODE_ID
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: CSI_ENDPOINT
          value: "unix://plugin/csi.sock"
        - name: KUBERNETES_CLUSTER_DOMAIN
          value: "cluster.local"
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        image: csi-rclone:latest
        imagePullPolicy: IfNotPresent
        # TODO: check if necessary
        lifecycle:
          postStart:
            exec:
              command:
              - /bin/sh
              - -c
              - mount -t fuse.rclone | while read -r mount; do umount $(echo $mount | awk {print $3}) ; done
        name: rclone
        resources:
            {}
        securityContext:
          allowPrivilegeEscalation: true
          capabilities:
            add:
            - SYS_ADMIN
          privileged: true
        volumeMounts:
        - mountPath: /plugin
          name: plugin-dir
        - mountPath: /var/lib/kubelet/pods
          mountPropagation: Bidirectional
          name: pods-mount-dir
      volumes:
      - hostPath:
          path: /var/lib/kubelet/plugins/csi-rclone
          type: DirectoryOrCreate
        name: plugin-dir
      - hostPath:
          path: /var/lib/kubelet/pods
          type: Directory
        name: pods-mount-dir
      - hostPath:
          path: /var/lib/kubelet/plugins_registry
          type: DirectoryOrCreate
        name: registration-dir
---
# Source: csi-rclone/templates/csi-controller-rclone.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: csi-rclone-controller
  namespace: csi-rclone
  labels:
    helm.sh/chart: csi-rclone-0.1.0
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: csi-controller-rclone
  serviceName: csi-rclone-controller
  template:
    metadata:
      labels:
        app: csi-controller-rclone
    spec:
      serviceAccountName: csi-rclone-controller
      containers:
      - args:
        - --v=5
        - --csi-address=$(ADDRESS)
        - --leader-election
        env:
        - name: ADDRESS
          value: "/csi/csi.sock"
        - name: KUBERNETES_CLUSTER_DOMAIN
          value: "cluster.local"
        image: k8s.gcr.io/sig-storage/csi-attacher:v3.4.0
        imagePullPolicy: IfNotPresent
        name: csi-attacher
        resources: {}
        volumeMounts:
        - mountPath: /csi
          name: socket-dir
      - args:
        - --csi-address=$(ADDRESS)
        - --capacity-ownerref-level=0
        - --extra-create-metadata
        env:
        - name: ADDRESS
          value: "/csi/csi.sock"
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        image: registry.k8s.io/sig-storage/csi-provisioner:v3.4.1
        imagePullPolicy: IfNotPresent
        name: csi-provisioner
        volumeMounts:
          - name: socket-dir
            mountPath: /csi
      - args:
        - /bin/csi-rclone-plugin
        - run
        - --nodeid=$(NODE_ID)
        - --endpoint=$(CSI_ENDPOINT)
        env:
        - name: NODE_ID
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: CSI_ENDPOINT
          value: "unix://plugin/csi.sock"
        - name: KUBERNETES_CLUSTER_DOMAIN
          value: "cluster.local"
        image: csi-rclone:latest
        imagePullPolicy: IfNotPresent
        name: rclone
        resources:
            {}
        volumeMounts:
        - mountPath: /plugin
          name: socket-dir
      volumes:
      - emptyDir: {}
        name: socket-dir
  updateStrategy: {}
---
# Source: csi-rclone/templates/csi-driver.yaml
apiVersion: storage.k8s.io/v1
kind: CSIDriver
metadata:
  name: csi-rclone-driver
  labels:
    helm.sh/chart: csi-rclone-0.1.0
    app.kubernetes.io/name: csi-rclone
    app.kubernetes.io/instance: csi-rclone
    app.kubernetes.io/version: "0.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  attachRequired: true
  podInfoOnMount: false  # are we sure about this?
  volumeLifecycleModes:
    - Persistent
    - Ephemeral
